{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Instructor - A few notes before we go on\n",
    "* Notebook by Adam Lang\n",
    "* Date: 3/19/2024\n",
    "* This notebook goes over some examples from the Instructor async documentation for asynchronous programming for structured LLM output using openai.\n",
    "    * These examples are part of the work I have been doing on structured LLM outputs.\n",
    "* Source: https://python.useinstructor.com/blog/2023/11/13/learn-async/#for-loop-running-tasks-sequentially\n",
    "1. The Instructor documentation recommends using `AsyncOpenAI` from the `openai` library. We need to import it, but no need to install, its already there.\n",
    "    * We will need to either write a new function or change the existing function for `azure_openai_client()` in the config file.\n",
    "    * I am not going to change the current function in the config file, I can rewrite it in this notebook for now.\n",
    "2. The Instructor docs also recommend using the `apatch` function call but this has since been deprecated in favor of `patch`. This is the line of code I am referring to:\n",
    "\n",
    "3. `apatch` Enables `response_model` in `create` method:\n",
    "    * client = instructor.apatch(AsyncOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting instructor\n",
      "  Downloading instructor-0.6.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1 (from instructor)\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting docstring-parser<0.16,>=0.15 (from instructor)\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting openai<2.0.0,>=1.1.0 (from instructor)\n",
      "  Downloading openai-1.14.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.2 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor) (2.5.2)\n",
      "Collecting rich<14.0.0,>=13.7.0 (from instructor)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.3 (from instructor)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.9.0 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor) (0.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.9.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.1.0->instructor) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.1.0->instructor) (1.8.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.1.0->instructor)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.1.0->instructor) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.1.0->instructor) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.1.0->instructor) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.0.2->instructor) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.0.2->instructor) (2.14.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.7.0->instructor)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\langadam\\appdata\\roaming\\python\\python311\\site-packages (from rich<14.0.0,>=13.7.0->instructor) (2.14.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.9.0->instructor) (8.1.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.1.0->instructor) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\langadam\\appdata\\roaming\\python\\python311\\site-packages (from click<9.0.0,>=7.1.1->typer<0.10.0,>=0.9.0->instructor) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor) (2023.5.7)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\langadam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.1.0->instructor) (0.14.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading instructor-0.6.4-py3-none-any.whl (39 kB)\n",
      "Downloading aiohttp-3.9.3-cp311-cp311-win_amd64.whl (365 kB)\n",
      "   ---------------------------------------- 0.0/365.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 365.3/365.3 kB 7.6 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
      "   ---------------------------------------- 0.0/262.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 262.4/262.4 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 240.7/240.7 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 71.7/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB 466.8 kB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.8/77.8 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: tenacity, mdurl, httpcore, docstring-parser, markdown-it-py, httpx, aiohttp, rich, openai, instructor\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.5\n",
      "    Uninstalling aiohttp-3.8.5:\n",
      "      Successfully uninstalled aiohttp-3.8.5\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.8\n",
      "    Uninstalling openai-0.27.8:\n",
      "      Successfully uninstalled openai-0.27.8\n",
      "Successfully installed aiohttp-3.9.3 docstring-parser-0.15 httpcore-1.0.4 httpx-0.27.0 instructor-0.6.4 markdown-it-py-3.0.0 mdurl-0.1.2 openai-1.14.2 rich-13.7.1 tenacity-8.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "semantic-kernel 0.3.1.dev0 requires openai<0.28.0,>=0.27.0, but you have openai 1.14.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os and instantiate openai key\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = '<your-api-key>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for AzureOpenAI you can use AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    async def __aexit__(self, *args, **kwargs):\n",
    "        self.end = time.time()\n",
    "        print(f\"{self.name} took {(self.end - self.start):.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import response\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field, HttpUrl\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Enables a response model in create method\n",
    "client = instructor.patch(AsyncOpenAI()) # using patch instead of apatch\n",
    "\n",
    "\n",
    "# base model class\n",
    "class Person (BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    email: str\n",
    "    # url: url_finder\n",
    "    skills: list[str] = Field(..., title=\"List of skills\")\n",
    "\n",
    "\n",
    "# function to extract person information\n",
    "async def extract_person(text: str) -> Person:\n",
    "    return await client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        response_model=Person,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "        \"My name is John and I am 20 years old, my email is john@gmail.com, my skills are Python, SQL and C#.\",\n",
    "        \"My name is Mary and I am 21 years old, my email is mary@yahoo.com, my skills are Go, Rust and C++.\",\n",
    "        \"My name is Bob and I am 22 years old, my email is bob@aol.com, my skills are node.js, react and angular.\",\n",
    "        \"My name is Alice and I am 23 years old, my email is Alice@aol.com, my skills are data science, machine learning and deep learning\",\n",
    "        \"My name is Jane and I am 24 years old, my email is Jane@aol.com, my skills are statistics, calculus and algebra\",\n",
    "        \"My name is Joe and I am 25 years old, my email is Joe@google.com, my skills are Java, C++ and JavaScript\",\n",
    "        \"My name is Jill and I am 26 years old my email is jill@mail.com, my skills are product management, project management and agile\",\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 comparison methods\n",
    "1. `for loop` using `asyncio.create_task()`\n",
    "2. `asyncio.gather`\n",
    "3. `asyncio.as_completed`\n",
    "4. `rate-limited gather - semaphores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asyncio.create_task: [Person(name='John', age=20, email='john@gmail.com', skills=['Python', 'SQL', 'C#']), Person(name='Mary', age=21, email='mary@yahoo.com', skills=['Go', 'Rust', 'C++']), Person(name='Bob', age=22, email='bob@aol.com', skills=['node.js', 'react', 'angular']), Person(name='Alice', age=23, email='Alice@aol.com', skills=['data science', 'machine learning', 'deep learning']), Person(name='Jane', age=24, email='Jane@aol.com', skills=['statistics', 'calculus', 'algebra']), Person(name='Joe', age=25, email='Joe@google.com', skills=['Java', 'C++', 'JavaScript']), Person(name='Jill', age=26, email='jill@mail.com', skills=['product management', 'project management', 'agile'])]\n",
      "asyncio.create_task took 7.06 seconds\n"
     ]
    }
   ],
   "source": [
    "## 1. \"for loop\" - simplest way but takes too long - runs sequential tasks - \"asyncio.create_task()\"\n",
    "async with Timer(\"asyncio.create_task\"):\n",
    "        all_persons = []\n",
    "        tasks_get_persons = [extract_person(text) for text in dataset]\n",
    "        for task in tasks_get_persons:\n",
    "            all_persons.append(await task)\n",
    "        print(\"asyncio.create_task:\", all_persons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asyncio.gather: [Person(name='John', age=20, email='john@gmail.com', skills=['Python', 'SQL', 'C#']), Person(name='Mary', age=21, email='mary@yahoo.com', skills=['Go', 'Rust', 'C++']), Person(name='Bob', age=22, email='bob@aol.com', skills=['node.js', 'react', 'angular']), Person(name='Alice', age=23, email='Alice@aol.com', skills=['data science', 'machine learning', 'deep learning']), Person(name='Jane', age=24, email='Jane@aol.com', skills=['statistics', 'calculus', 'algebra']), Person(name='Joe', age=25, email='Joe@google.com', skills=['Java', 'C++', 'JavaScript']), Person(name='Jill', age=26, email='jill@mail.com', skills=['product management', 'project management', 'agile'])]\n",
      "asyncio.gather took 1.32 seconds\n"
     ]
    }
   ],
   "source": [
    "## 2. \"asyncio.gather\" - Batch processing - runs concurrently\n",
    "async with Timer(\"asyncio.gather\"):\n",
    "        tasks_get_persons = [extract_person(text) for text in dataset]\n",
    "        all_person = await asyncio.gather(*tasks_get_persons)\n",
    "        print(\"asyncio.gather:\", all_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asyncio.as_completed: [Person(name='Jane', age=24), Person(name='Joe', age=25), Person(name='John', age=20), Person(name='Mary', age=21), Person(name='Alice', age=23), Person(name='Bob', age=22), Person(name='Jill', age=26)]\n",
      "asyncio.as_completed took 1.18 seconds\n"
     ]
    }
   ],
   "source": [
    "## 3. \"asyncio.as_completed\" - faster than asyncio.gather - runs tasks as completed\n",
    "async with Timer(\"asyncio.as_completed\"):\n",
    "        all_persons = []\n",
    "        tasks_get_persons = [extract_person(text) for text in dataset]\n",
    "        for person in asyncio.as_completed(tasks_get_persons):\n",
    "            all_persons.append(await person)\n",
    "        print(\"asyncio.as_completed:\", all_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Semaphore allows 2 concurrent requests - limits the number of concurrent requests\n",
    "sem = asyncio.Semaphore(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asyncio.gather (rate limited): [Person(name='John', age=20), Person(name='Mary', age=21), Person(name='Bob', age=22), Person(name='Alice', age=23), Person(name='Jane', age=24), Person(name='Joe', age=25), Person(name='Jill', age=26)]\n",
      "asyncio.gather (rate limited) took 2.83 seconds\n",
      "asyncio.as_completed (rate limited): [Person(name='Joe', age=25), Person(name='Jane', age=24), Person(name='Jill', age=26), Person(name='Mary', age=21), Person(name='Bob', age=22), Person(name='John', age=20), Person(name='Alice', age=23)]\n",
      "asyncio.as_completed (rate limited) took 2.93 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create a semaphore that will only allow 2 concurrent requests\n",
    "\n",
    "async def rate_limited_extract_person(text: str) -> Person:\n",
    "        async with sem:\n",
    "            return await extract_person(text)\n",
    "\n",
    "async with Timer(\"asyncio.gather (rate limited)\"):\n",
    "        tasks_get_persons = [rate_limited_extract_person(text) for text in dataset]\n",
    "        resp = await asyncio.gather(*tasks_get_persons)\n",
    "        print(\"asyncio.gather (rate limited):\", resp)\n",
    "\n",
    "async with Timer(\"asyncio.as_completed (rate limited)\"):\n",
    "        all_persons = []\n",
    "        tasks_get_persons = [rate_limited_extract_person(text) for text in dataset]\n",
    "        for person in asyncio.as_completed(tasks_get_persons):\n",
    "            all_persons.append(await person)\n",
    "        print(\"asyncio.as_completed (rate limited):\", all_persons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "1. `asyncio.gather` - multiple independent tasks quickly\n",
    "2. `asyncio.as_completed` for LARGE datasets to process tasks as they complete\n",
    "3. `rate-limiting` to avoid flooding or overwhelming the mongoDB server or API endpoints => this is probably what we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example function for using AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI, AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_azure_openai_client(self) -> AsyncAzureOpenAI:\n",
    "        kwargs: dict[str, Any] = {\n",
    "            \"azure_endpoint\": str(self.openai_api_base),\n",
    "            \"api_key\": self.openai_api_key,\n",
    "            \"api_version\": self.openai_api_version,\n",
    "        }\n",
    "        empty_kwargs = {k for k, v in kwargs.items() if v is None}\n",
    "        if empty_kwargs:\n",
    "            raise ValueError(f\"Cannot create Azure OpenAI connection: missing required args: {empty_kwargs}\")\n",
    "        return AsyncOpenAI(**kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
